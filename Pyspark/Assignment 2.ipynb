{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT 5202 - Data processing for Big Data Assignment 2\n",
    "\n",
    "## Submitted By : Hitesh Get\n",
    "## Student ID : 29637333\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01: Import Spark Session and initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "if (sc is None):\n",
    "    sc = SparkContext(master=\"local[4]\", appName=\"Assignment 2\")\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02: Load the dataset and print the schema and total number of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weatherAUS = spark.read.csv('weatherAUS.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "|               Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
      "+-------------------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "|2008-12-01 00:00:00|  Albury|   13.4|   22.9|     0.6|         NA|      NA|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       8|      NA|   16.9|   21.8|       No|          No|\n",
      "|2008-12-02 00:00:00|  Albury|    7.4|   25.1|       0|         NA|      NA|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|      NA|      NA|   17.2|   24.3|       No|          No|\n",
      "|2008-12-03 00:00:00|  Albury|   12.9|   25.7|       0|         NA|      NA|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|      NA|       2|     21|   23.2|       No|          No|\n",
      "|2008-12-04 00:00:00|  Albury|    9.2|     28|       0|         NA|      NA|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|      NA|      NA|   18.1|   26.5|       No|          No|\n",
      "|2008-12-05 00:00:00|  Albury|   17.5|   32.3|       1|         NA|      NA|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|       1006|       7|       8|   17.8|   29.7|       No|          No|\n",
      "|2008-12-06 00:00:00|  Albury|   14.6|   29.7|     0.2|         NA|      NA|        WNW|           56|         W|         W|          19|          24|         55|         23|     1009.2|     1005.4|      NA|      NA|   20.6|   28.9|       No|          No|\n",
      "|2008-12-07 00:00:00|  Albury|   14.3|     25|       0|         NA|      NA|          W|           50|        SW|         W|          20|          24|         49|         19|     1009.6|     1008.2|       1|      NA|   18.1|   24.6|       No|          No|\n",
      "|2008-12-08 00:00:00|  Albury|    7.7|   26.7|       0|         NA|      NA|          W|           35|       SSE|         W|           6|          17|         48|         19|     1013.4|     1010.1|      NA|      NA|   16.3|   25.5|       No|          No|\n",
      "|2008-12-09 00:00:00|  Albury|    9.7|   31.9|       0|         NA|      NA|        NNW|           80|        SE|        NW|           7|          28|         42|          9|     1008.9|     1003.6|      NA|      NA|   18.3|   30.2|       No|         Yes|\n",
      "|2008-12-10 00:00:00|  Albury|   13.1|   30.1|     1.4|         NA|      NA|          W|           28|         S|       SSE|          15|          11|         58|         27|       1007|     1005.7|      NA|      NA|   20.1|   28.2|      Yes|          No|\n",
      "+-------------------+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Date: timestamp, Location: string, MinTemp: string, MaxTemp: string, Rainfall: string, Evaporation: string, Sunshine: string, WindGustDir: string, WindGustSpeed: string, WindDir9am: string, WindDir3pm: string, WindSpeed9am: string, WindSpeed3pm: string, Humidity9am: string, Humidity3pm: string, Pressure9am: string, Pressure3pm: string, Cloud9am: string, Cloud3pm: string, Temp9am: string, Temp3pm: string, RainToday: string, RainTomorrow: string]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142193"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Count of entries\n",
    "df_weatherAUS.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 03: Delete columns from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Date','Location','Evaporation','Sunshine','Cloud9am','Cloud3pm','Temp9am','Temp3pm']\n",
    "df_weatherAUS_new = df_weatherAUS.drop(*drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|   13.4|   22.9|     0.6|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       No|          No|\n",
      "|    7.4|   25.1|       0|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|       No|          No|\n",
      "|   12.9|   25.7|       0|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|       No|          No|\n",
      "|    9.2|     28|       0|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|       No|          No|\n",
      "|   17.5|   32.3|       1|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|       1006|       No|          No|\n",
      "|   14.6|   29.7|     0.2|        WNW|           56|         W|         W|          19|          24|         55|         23|     1009.2|     1005.4|       No|          No|\n",
      "|   14.3|     25|       0|          W|           50|        SW|         W|          20|          24|         49|         19|     1009.6|     1008.2|       No|          No|\n",
      "|    7.7|   26.7|       0|          W|           35|       SSE|         W|           6|          17|         48|         19|     1013.4|     1010.1|       No|          No|\n",
      "|    9.7|   31.9|       0|        NNW|           80|        SE|        NW|           7|          28|         42|          9|     1008.9|     1003.6|       No|         Yes|\n",
      "|   13.1|   30.1|     1.4|          W|           28|         S|       SSE|          15|          11|         58|         27|       1007|     1005.7|      Yes|          No|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS_new.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 04: Print the number of missing data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|    637|    322|    1406|       9330|         9270|     10013|      3778|        1348|        2630|       1774|       3610|      14014|      13981|     1406|           0|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS_new.select([count(when(col(each) == 'NA', each)).alias(each) for each in df_weatherAUS_new.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 05: Fill the missing data with average value and maximum occurrence value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for all the numerical columns\n",
    "temp_columns = ['MinTemp','MaxTemp','Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type casting the numerical columns\n",
    "df_weatherAUS_new = df_weatherAUS_new.select(*(col(each).cast(\"double\").alias(each)if each in temp_columns else each\n",
    "                                               for each in df_weatherAUS_new.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[MinTemp: double, MaxTemp: double, Rainfall: double, WindGustDir: string, WindGustSpeed: double, WindDir9am: string, WindDir3pm: string, WindSpeed9am: double, WindSpeed3pm: double, Humidity9am: double, Humidity3pm: double, Pressure9am: double, Pressure3pm: double, RainToday: string, RainTomorrow: string]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|   13.4|   22.9|     0.6|          W|         44.0|         W|       WNW|        20.0|        24.0|       71.0|       22.0|     1007.7|     1007.1|       No|          No|\n",
      "|    7.4|   25.1|     0.0|        WNW|         44.0|       NNW|       WSW|         4.0|        22.0|       44.0|       25.0|     1010.6|     1007.8|       No|          No|\n",
      "|   12.9|   25.7|     0.0|        WSW|         46.0|         W|       WSW|        19.0|        26.0|       38.0|       30.0|     1007.6|     1008.7|       No|          No|\n",
      "|    9.2|   28.0|     0.0|         NE|         24.0|        SE|         E|        11.0|         9.0|       45.0|       16.0|     1017.6|     1012.8|       No|          No|\n",
      "|   17.5|   32.3|     1.0|          W|         41.0|       ENE|        NW|         7.0|        20.0|       82.0|       33.0|     1010.8|     1006.0|       No|          No|\n",
      "|   14.6|   29.7|     0.2|        WNW|         56.0|         W|         W|        19.0|        24.0|       55.0|       23.0|     1009.2|     1005.4|       No|          No|\n",
      "|   14.3|   25.0|     0.0|          W|         50.0|        SW|         W|        20.0|        24.0|       49.0|       19.0|     1009.6|     1008.2|       No|          No|\n",
      "|    7.7|   26.7|     0.0|          W|         35.0|       SSE|         W|         6.0|        17.0|       48.0|       19.0|     1013.4|     1010.1|       No|          No|\n",
      "|    9.7|   31.9|     0.0|        NNW|         80.0|        SE|        NW|         7.0|        28.0|       42.0|        9.0|     1008.9|     1003.6|       No|         Yes|\n",
      "|   13.1|   30.1|     1.4|          W|         28.0|         S|       SSE|        15.0|        11.0|       58.0|       27.0|     1007.0|     1005.7|      Yes|          No|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS_new.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to impute the mean value for the missing values in categorical columns\n",
    "def imputer_mean(df,col_list):\n",
    "    for each in col_list:\n",
    "        mean_val = df.agg({each: 'mean'}).collect()[0][0]\n",
    "        df = df.fillna(mean_val, subset=[each])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the average valur for null values\n",
    "df_weatherAUS_new = imputer_mean(df_weatherAUS_new,temp_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new.where(df_weatherAUS_new['MaxTemp'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new.where(df_weatherAUS_new['Rainfall'].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new.select(df_weatherAUS_new['RainToday']).groupBy('RainToday').count().sort(desc(\"count\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(RainToday='No', count=109332),\n",
       " Row(RainToday='Yes', count=31455),\n",
       " Row(RainToday='NA', count=1406)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new.select(df_weatherAUS_new['RainToday']).groupBy('RainToday').count().sort(desc(\"count\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "col_mode = df_weatherAUS_new.select(df_weatherAUS_new['RainToday']).groupBy('RainToday').count().sort(desc(\"count\")).collect()[0][0]\n",
    "print(col_mode)\n",
    "df_weatherAUS_new_temp = df_weatherAUS_new.withColumn(\"RainToday\", \\\n",
    "              when(df_weatherAUS_new[\"RainToday\"] == \"NA\", col_mode).otherwise(df_weatherAUS_new[\"RainToday\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(RainToday='No', count=110738), Row(RainToday='Yes', count=31455)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new_temp.select(df_weatherAUS_new_temp['RainToday']).groupBy('RainToday').count().sort(desc(\"count\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to replace null value with the mode value for non numerical columns\n",
    "def mode(df,col_list1):\n",
    "    for each in col_list1:\n",
    "        col_mode = df.select(df[each]).groupBy(each).count().sort(desc(\"count\")).collect()[0][0]\n",
    "        #print(col_mode)\n",
    "        df = df.withColumn(each,when(df_weatherAUS_new[each] == \"NA\", col_mode).otherwise(df[each]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for the non numerical columns\n",
    "str_cols = ['WindGustDir','WindDir9am','WindDir3pm','RainToday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the mode value for the null values in non categorical columns\n",
    "df_weatherAUS_new = mode(df_weatherAUS_new,str_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[MinTemp: double, MaxTemp: double, Rainfall: double, WindGustDir: string, WindGustSpeed: double, WindDir9am: string, WindDir3pm: string, WindSpeed9am: double, WindSpeed3pm: double, Humidity9am: double, Humidity3pm: double, Pressure9am: double, Pressure3pm: double, RainToday: string, RainTomorrow: string]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weatherAUS_new.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06: Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pypsark machine learning module functions\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoderEstimator,VectorAssembler\n",
    "\n",
    "# Creating an empty list\n",
    "levels = []\n",
    "\n",
    "\n",
    "# Running loop for encoding categorical columns\n",
    "for c in str_cols:\n",
    "    indexers = StringIndexer(inputCol=c, outputCol=c+\"_index\")\n",
    "    encoders = OneHotEncoderEstimator(inputCols=[indexers.getOutputCol()], outputCols = [c+\"_ohe\"])\n",
    "    levels += [indexers,encoders]\n",
    "\n",
    "# Converting the label using string indexer\n",
    "label_indexer = StringIndexer(inputCol = 'RainTomorrow', outputCol = 'label')\n",
    "levels += [label_indexer]\n",
    "\n",
    "# Using the vector assembler to generate one single vector column from all the feature columns\n",
    "input_assemble = [c + \"_ohe\" for c in str_cols] + temp_columns\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_assemble, outputCol=\"features\")\n",
    "levels += [assembler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm']\n"
     ]
    }
   ],
   "source": [
    "print(temp_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 07: Create the feature vector and divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- MinTemp: double (nullable = false)\n",
      " |-- MaxTemp: double (nullable = false)\n",
      " |-- Rainfall: double (nullable = false)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: double (nullable = false)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: double (nullable = false)\n",
      " |-- WindSpeed3pm: double (nullable = false)\n",
      " |-- Humidity9am: double (nullable = false)\n",
      " |-- Humidity3pm: double (nullable = false)\n",
      " |-- Pressure9am: double (nullable = false)\n",
      " |-- Pressure3pm: double (nullable = false)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a pipeline to combine transformers and estimators\n",
    "pipeline = Pipeline(stages=levels)\n",
    "# Fitting the pipeline model\n",
    "pipeline_model = pipeline.fit(df_weatherAUS_new)\n",
    "# Transforming and cerating new data frame\n",
    "df_weatherAUS_new_transormed = pipeline_model.transform(df_weatherAUS_new)\n",
    "# Adding faetures and labels columns to the transformed dataframe\n",
    "cols = df_weatherAUS_new.columns\n",
    "cols_selected = ['label', 'features'] + cols\n",
    "df_weatherAUS_new_transormed = df_weatherAUS_new_transormed.select(cols_selected)\n",
    "df_weatherAUS_new_transormed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------+-------+------------------+-----------+-------------+----------+----------+---------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|label|            features|MinTemp|MaxTemp|          Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|   WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-----+--------------------+-------+-------+------------------+-----------+-------------+----------+----------+---------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|  0.0|(56,[0,21,37,45,4...|   13.4|   22.9|               0.6|          W|         44.0|         W|       WNW|           20.0|        24.0|       71.0|       22.0|     1007.7|     1007.1|       No|          No|\n",
      "|  0.0|(56,[9,24,33,45,4...|    7.4|   25.1|               0.0|        WNW|         44.0|       NNW|       WSW|            4.0|        22.0|       44.0|       25.0|     1010.6|     1007.8|       No|          No|\n",
      "|  0.0|(56,[6,21,33,45,4...|   12.9|   25.7|               0.0|        WSW|         46.0|         W|       WSW|           19.0|        26.0|       38.0|       30.0|     1007.6|     1008.7|       No|          No|\n",
      "|  0.0|(56,[13,16,40,45,...|    9.2|   28.0|               0.0|         NE|         24.0|        SE|         E|           11.0|         9.0|       45.0|       16.0|     1017.6|     1012.8|       No|          No|\n",
      "|  0.0|(56,[0,25,38,45,4...|   17.5|   32.3|               1.0|          W|         41.0|       ENE|        NW|            7.0|        20.0|       82.0|       33.0|     1010.8|     1006.0|       No|          No|\n",
      "|  0.0|(56,[9,21,31,45,4...|   14.6|   29.7|               0.2|        WNW|         56.0|         W|         W|           19.0|        24.0|       55.0|       23.0|     1009.2|     1005.4|       No|          No|\n",
      "|  0.0|(56,[0,22,31,45,4...|   14.3|   25.0|               0.0|          W|         50.0|        SW|         W|           20.0|        24.0|       49.0|       19.0|     1009.6|     1008.2|       No|          No|\n",
      "|  0.0|(56,[0,18,31,45,4...|    7.7|   26.7|               0.0|          W|         35.0|       SSE|         W|            6.0|        17.0|       48.0|       19.0|     1013.4|     1010.1|       No|          No|\n",
      "|  1.0|(56,[14,16,38,45,...|    9.7|   31.9|               0.0|        NNW|         80.0|        SE|        NW|            7.0|        28.0|       42.0|        9.0|     1008.9|     1003.6|       No|         Yes|\n",
      "|  0.0|(56,[0,20,35,46,4...|   13.1|   30.1|               1.4|          W|         28.0|         S|       SSE|           15.0|        11.0|       58.0|       27.0|     1007.0|     1005.7|      Yes|          No|\n",
      "|  1.0|(56,[3,18,39,45,4...|   13.4|   30.4|               0.0|          N|         30.0|       SSE|       ESE|           17.0|         6.0|       48.0|       22.0|     1011.8|     1008.7|       No|         Yes|\n",
      "|  1.0|(56,[27,44,46,47,...|   15.9|   21.7|               2.2|        NNE|         31.0|        NE|       ENE|           15.0|        13.0|       89.0|       91.0|     1010.5|     1004.2|      Yes|         Yes|\n",
      "|  1.0|(56,[0,24,43,46,4...|   15.9|   18.6|              15.6|          W|         61.0|       NNW|       NNW|           28.0|        28.0|       76.0|       93.0|      994.3|      993.0|      Yes|         Yes|\n",
      "|  0.0|(56,[7,21,42,46,4...|   12.6|   21.0|               3.6|         SW|         44.0|         W|       SSW|           24.0|        20.0|       65.0|       43.0|     1001.2|     1001.8|      Yes|          No|\n",
      "|  0.0|(56,[9,15,37,45,4...|    9.8|   27.7|2.3499740743107256|        WNW|         50.0|         N|       WNW|14.001988000994|        22.0|       50.0|       28.0|     1013.4|     1010.3|       No|          No|\n",
      "|  1.0|(56,[11,28,40,45,...|   14.1|   20.9|               0.0|        ENE|         22.0|       SSW|         E|           11.0|         9.0|       69.0|       82.0|     1012.2|     1010.4|       No|         Yes|\n",
      "|  1.0|(56,[0,15,37,46,4...|   13.5|   22.9|              16.8|          W|         63.0|         N|       WNW|            6.0|        20.0|       80.0|       65.0|     1005.8|     1002.2|      Yes|         Yes|\n",
      "|  0.0|(56,[4,34,46,47,4...|   11.2|   22.5|              10.6|        SSE|         43.0|       WSW|        SW|           24.0|        17.0|       47.0|       32.0|     1009.4|     1009.7|      Yes|          No|\n",
      "|  0.0|(56,[4,16,43,45,4...|    9.8|   25.6|               0.0|        SSE|         26.0|        SE|       NNW|           17.0|         6.0|       45.0|       26.0|     1019.2|     1017.1|       No|          No|\n",
      "|  0.0|(56,[5,16,30,45,4...|   11.5|   29.3|               0.0|          S|         24.0|        SE|        SE|            9.0|         9.0|       56.0|       28.0|     1019.3|     1014.8|       No|          No|\n",
      "|  0.0|(56,[13,27,36,45,...|   17.1|   33.0|               0.0|         NE|         43.0|        NE|         N|           17.0|        22.0|       38.0|       28.0|     1013.6|     1008.1|       No|          No|\n",
      "|  0.0|(56,[9,21,31,45,4...|   20.5|   31.8|               0.0|        WNW|         41.0|         W|         W|           19.0|        20.0|       54.0|       24.0|     1007.8|     1005.7|       No|          No|\n",
      "|  0.0|(56,[3,26,38,45,4...|   15.3|   30.9|               0.0|          N|         33.0|       ESE|        NW|            6.0|        13.0|       55.0|       23.0|     1011.0|     1008.2|       No|          No|\n",
      "|  0.0|(56,[0,17,31,45,4...|   12.6|   32.4|               0.0|          W|         43.0|         E|         W|            4.0|        19.0|       49.0|       17.0|     1012.9|     1010.1|       No|          No|\n",
      "|  0.0|(56,[6,16,33,45,4...|   16.2|   33.9|               0.0|        WSW|         35.0|        SE|       WSW|            9.0|        13.0|       45.0|       19.0|     1010.9|     1007.6|       No|          No|\n",
      "|  0.0|(56,[6,15,31,45,4...|   16.9|   33.0|               0.0|        WSW|         57.0|         N|         W|            0.0|        26.0|       41.0|       28.0|     1006.8|     1003.6|       No|          No|\n",
      "|  0.0|(56,[9,15,37,45,4...|   20.1|   32.7|               0.0|        WNW|         48.0|         N|       WNW|           13.0|        30.0|       56.0|       15.0|     1005.2|     1001.7|       No|          No|\n",
      "|  1.0|(56,[9,19,33,45,4...|   19.7|   27.2|               0.0|        WNW|         46.0|        NW|       WSW|           19.0|        30.0|       49.0|       22.0|     1004.8|     1004.2|       No|         Yes|\n",
      "|  0.0|(56,[9,34,46,47,4...|   12.5|   24.2|               1.2|        WNW|         50.0|       WSW|        SW|           11.0|        22.0|       78.0|       70.0|     1005.6|     1003.4|      Yes|          No|\n",
      "|  0.0|(56,[0,29,37,45,4...|   12.0|   24.4|               0.8|          W|         39.0|       WNW|       WNW|           17.0|        17.0|       48.0|       28.0|     1006.1|     1005.1|       No|          No|\n",
      "|  0.0|(56,[9,21,37,45,4...|   11.3|   26.5|               0.0|        WNW|         56.0|         W|       WNW|           19.0|        31.0|       46.0|       26.0|     1004.5|     1003.2|       No|          No|\n",
      "|  0.0|(56,[0,42,45,46,4...|    9.6|   23.9|               0.0|          W|         41.0|       WSW|       SSW|           19.0|        11.0|       44.0|       22.0|     1014.4|     1013.1|       No|          No|\n",
      "|  0.0|(56,[4,18,40,45,4...|   10.5|   28.8|               0.0|        SSE|         26.0|       SSE|         E|           11.0|         7.0|       43.0|       22.0|     1018.7|     1014.8|       No|          No|\n",
      "|  0.0|(56,[9,18,38,45,4...|   12.3|   34.6|               0.0|        WNW|         37.0|       SSE|        NW|            6.0|        17.0|       41.0|       12.0|     1015.1|     1010.3|       No|          No|\n",
      "|  0.0|(56,[9,25,38,45,4...|   12.9|   35.8|               0.0|        WNW|         41.0|       ENE|        NW|            6.0|        26.0|       41.0|        9.0|     1012.6|     1009.2|       No|          No|\n",
      "|  0.0|(56,[0,16,37,45,4...|   13.7|   37.9|               0.0|          W|         52.0|        SE|       WNW|            4.0|        26.0|       33.0|        8.0|     1010.9|     1006.7|       No|          No|\n",
      "|  0.0|(56,[0,17,31,45,4...|   16.1|   38.9|               0.0|          W|         57.0|         E|         W|            6.0|        30.0|       34.0|       12.0|     1007.0|     1002.7|       No|          No|\n",
      "|  0.0|(56,[0,21,33,45,4...|   14.0|   28.3|               0.0|          W|         48.0|         W|       WSW|           17.0|        24.0|       43.0|       15.0|     1011.9|     1010.9|       No|          No|\n",
      "|  0.0|(56,[13,18,32,45,...|   12.5|   28.4|               0.0|         NE|         37.0|       SSE|         S|           20.0|         9.0|       38.0|       16.0|     1017.8|     1013.7|       No|          No|\n",
      "|  0.0|(56,[13,23,40,45,...|   17.0|   30.8|               0.0|         NE|         37.0|       NNE|         E|           15.0|        11.0|       36.0|       24.0|     1013.4|     1008.1|       No|          No|\n",
      "|  0.0|(56,[5,18,36,45,4...|   16.9|   32.0|               0.0|          S|         31.0|       SSE|         N|           13.0|        17.0|       52.0|       31.0|     1009.9|     1006.8|       No|          No|\n",
      "|  0.0|(56,[7,16,33,45,4...|   17.3|   34.7|               0.0|         SW|         35.0|        SE|       WSW|            7.0|        15.0|       48.0|       16.0|     1014.1|     1012.1|       No|          No|\n",
      "|  0.0|(56,[14,16,38,45,...|   17.2|   37.7|               0.0|        NNW|         35.0|        SE|        NW|            7.0|        17.0|       51.0|       19.0|     1015.7|     1010.9|       No|          No|\n",
      "|  0.0|(56,[10,18,42,45,...|   17.4|   43.0|               0.0|         NW|         39.0|       SSE|       SSW|            7.0|        17.0|       40.0|        8.0|     1011.6|     1006.9|       No|          No|\n",
      "|  0.0|(56,[9,21,31,45,4...|   19.8|   32.7|               0.0|        WNW|         44.0|         W|         W|           20.0|        28.0|       34.0|       28.0|     1008.4|     1009.2|       No|          No|\n",
      "|  0.0|(56,[7,34,45,46,4...|   14.9|   26.7|               0.0|         SW|         56.0|       WSW|        SW|           20.0|        31.0|       46.0|       20.0|     1014.1|     1012.7|       No|          No|\n",
      "|  0.0|(56,[1,16,34,45,4...|   10.5|   28.4|               0.0|         SE|         33.0|        SE|        SW|           19.0|        11.0|       35.0|       16.0|     1019.7|     1017.4|       No|          No|\n",
      "|  0.0|(56,[9,25,42,45,4...|   11.3|   32.2|               0.0|        WNW|         28.0|       ENE|       SSW|           17.0|        15.0|       34.0|       17.0|     1019.7|     1016.2|       No|          No|\n",
      "|  0.0|(56,[9,18,45,46,4...|   13.9|   36.6|               0.0|        WNW|         39.0|       SSE|       NNE|            2.0|        15.0|       39.0|       10.0|     1015.8|     1010.6|       No|          No|\n",
      "|  0.0|(56,[14,18,37,45,...|   18.6|   39.9|               0.0|        NNW|         61.0|       SSE|       WNW|            9.0|        20.0|       36.0|       21.0|     1010.1|     1004.8|       No|          No|\n",
      "+-----+--------------------+-------+-------+------------------+-----------+-------------+----------+----------+---------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weatherAUS_new_transormed.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train ans test data\n",
    "train_data, test_data = df_weatherAUS_new_transormed.randomSplit([0.7, 0.3], seed = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08 and Step 09: Apply machine learning classification algorithms on the dataset and compare their accuracy. Plot the accuracy as bar graph. Calculate the confusion matrix and find the precision, recall, and F1 score of each classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+-----+--------------------+\n",
      "|MaxTemp|prediction|    rawPrediction|label|         probability|\n",
      "+-------+----------+-----------------+-----+--------------------+\n",
      "|   19.3|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   19.1|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   18.9|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   18.7|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   28.7|       0.0|  [3526.0,2262.0]|  0.0|[0.60919143054595...|\n",
      "|   21.3|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   26.2|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   22.4|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   22.8|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   26.8|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   28.2|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   27.7|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   28.0|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   18.2|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   19.2|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   19.0|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   22.8|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   20.8|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   21.4|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "|   24.9|       0.0|[70880.0,12131.0]|  0.0|[0.85386274108250...|\n",
      "+-------+----------+-----------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      " The accuracy of decision tree model is0.8293196165536592\n",
      "{'Decision Tree': 0.8293196165536592}\n",
      "Test Error = 0.17068 \n"
     ]
    }
   ],
   "source": [
    "# importing the machine learning modules\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Creating an empty dictionary to capture all ML model accuracies\n",
    "model_accuracy = {}\n",
    "\n",
    "# Implementing decision tree and fitting the model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\",maxDepth = 3)\n",
    "model_dt = dt.fit(train_data)\n",
    "\n",
    "# Transorming the data\n",
    "predictions_dt = model_dt.transform(test_data)\n",
    "\n",
    "# Displaying the predictions\n",
    "predictions_dt.select(\"prediction\",\"rawPrediction\", \"label\",\"probability\").show(20)\n",
    "\n",
    "# Creating the evaluator to calculate the model accuracy\n",
    "evaluator_dt = MulticlassClassificationEvaluator(\\\n",
    "\n",
    "labelCol=\"label\", predictionCol=\"prediction\",\\\n",
    "\n",
    "metricName=\"accuracy\")\n",
    "\n",
    "accuracy_dt = evaluator_dt.evaluate(predictions_dt)\n",
    "\n",
    "print(\" The accuracy of decision tree model is \" + str(accuracy_dt))\n",
    "\n",
    "model_accuracy[\"Decision Tree\"] = accuracy_dt\n",
    "\n",
    "print(model_accuracy)\n",
    "               \n",
    "\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to calculate confusion matrix,precision, recall and F1 score\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print('Confusion Matrix\\n', metrics.confusionMatrix().toArray())\n",
    "    c_mat=metrics.confusionMatrix().toArray()\n",
    "    precision_false=(c_mat[0][0])/(c_mat[0][0]+c_mat[1][0])\n",
    "    precision_true=(c_mat[1][1])/(c_mat[1][1]+c_mat[0][1])    \n",
    "    recall_false=(c_mat[0][0])/(c_mat[0][0]+c_mat[0][1])\n",
    "    recall_true=(c_mat[1][1])/(c_mat[1][1]+c_mat[1][0]) \n",
    "    f1_score = (2* c_mat[0][0])/(2*c_mat[0][0]+c_mat[0][1]+c_mat[1][0])\n",
    "    \n",
    "    print(\"The precision of False is \",str(precision_false))\n",
    "    print(\"The precision of True is \",str(precision_true))\n",
    "    print(\"The recall of True is \",str(recall_true))\n",
    "    print(\"The recall of False is \",str(recall_false))\n",
    "    print(\"The F1-score is \",str(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[32046.  1136.]\n",
      " [ 6164.  3424.]]\n",
      "The precision of False is  0.838680973567129\n",
      "The precision of True is  0.7508771929824561\n",
      "The recall of True is  0.3571130579891531\n",
      "The recall of False is  0.9657645711530348\n",
      "0.8977476467951591\n",
      "The F1-score is  0.8977476467951592\n"
     ]
    }
   ],
   "source": [
    "# Creating prediction and label rdd\n",
    "predictionAndLabel_dt = predictions_dt.select(\"prediction\", \"label\").rdd\n",
    "printMetrics(predictionAndLabel_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "The random forest model accuracy is:0.8283610007014263\n",
      "Test Error = 0.171639\n"
     ]
    }
   ],
   "source": [
    "# importing the machine learning modules\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Creating a random forest model\n",
    "rf = RandomForestClassifier(labelCol=\"label\",\\\n",
    "featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# Fitting the model\n",
    "model_rf = rf.fit(train_data)\n",
    "\n",
    "# Transforming the data\n",
    "predictions_rf = model_rf.transform(test_data)\n",
    "\n",
    "predictions_rf.select(\"prediction\", \"label\",\"rawPrediction\",\"probability\").show(10)\n",
    "\n",
    "# Evaluating model performance\n",
    "evaluator_rf =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Calculating model accuracy\n",
    "accuracy_rf = evaluator_rf.evaluate(predictions_rf)\n",
    "\n",
    "print(\"The random forest model accuracy is:\"+ str(accuracy_rf))\n",
    "\n",
    "model_accuracy[\"Random Forest\"] = accuracy_rf\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[32320.   862.]\n",
      " [ 6479.  3109.]]\n",
      "The precision of False is  0.8330111600814454\n",
      "The precision of True is  0.782926215059179\n",
      "The recall of True is  0.32425949103045476\n",
      "The recall of False is  0.974022060153095\n",
      "0.8980147538933885\n",
      "The F1-score is  0.8980147538933886\n"
     ]
    }
   ],
   "source": [
    "# Creating perdiction and label rdd\n",
    "predictionAndLabel_rf = predictions_rf.select(\"prediction\", \"label\").rdd\n",
    "printMetrics(predictionAndLabel_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+\n",
      "|label|       rawPrediction|prediction|         probability|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "|  0.0|[1.63146140787279...|       0.0|[0.83636973866221...|\n",
      "|  0.0|[0.90531326451071...|       0.0|[0.71204015511253...|\n",
      "|  0.0|[1.26671843689595...|       0.0|[0.78018048092537...|\n",
      "|  0.0|[0.64546712329793...|       0.0|[0.65598826350991...|\n",
      "|  0.0|[1.01230890011041...|       0.0|[0.73347176153072...|\n",
      "|  0.0|[1.06551462828954...|       0.0|[0.74374298673333...|\n",
      "|  0.0|[0.97995508681246...|       0.0|[0.72709930449210...|\n",
      "|  0.0|[0.88687579896153...|       0.0|[0.70824502663725...|\n",
      "|  0.0|[1.06081803796338...|       0.0|[0.74284684238191...|\n",
      "|  0.0|[0.99779017180217...|       0.0|[0.73062387825488...|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The logistic regression model accuracy is:0.8183773673135375\n"
     ]
    }
   ],
   "source": [
    "# Importing machine learning modules\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Creating logistic Regression model\n",
    "log_reg = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "model_lr = log_reg.fit(train_data)\n",
    "\n",
    "# Transforming the data\n",
    "predictions_lr = model_lr.transform(test_data)\n",
    " \n",
    "predictions_lr.select('label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "\n",
    "# Evaluating model performance\n",
    "evaluator_lr =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Calculating model accuracy\n",
    "accuracy_lr = evaluator_lr.evaluate(predictions_lr)\n",
    "\n",
    "print(\"The logistic regression model accuracy is:\"+ str(accuracy_lr))\n",
    "\n",
    "model_accuracy[\"Logistic Regression\"] = accuracy_lr\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of True  0.6435331230283912\n",
      "Precision of False 0.8488059291792479\n",
      "Recall of True     0.425531914893617\n",
      "Recall of False    0.9318907841600867\n",
      "F-1 Score          0.8183773673135375\n",
      "Confusion Matrix\n",
      " [[30922.  2260.]\n",
      " [ 5508.  4080.]]\n"
     ]
    }
   ],
   "source": [
    "# Creating prediction and label rdd\n",
    "predictionAndLabel_lr = predictions_lr.select(\"prediction\", \"label\").rdd\n",
    "printMetrics(predictionAndLabel_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+--------------------+\n",
      "|label|       rawPrediction|prediction|         probability|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "|  0.0|[0.92081090920191...|       0.0|[0.86314040414413...|\n",
      "|  0.0|[0.73738808367270...|       0.0|[0.81378225472440...|\n",
      "|  0.0|[0.81811450921302...|       0.0|[0.83702116599149...|\n",
      "|  0.0|[0.65861635163657...|       0.0|[0.78872093201948...|\n",
      "|  0.0|[0.37866927172315...|       0.0|[0.68077562407350...|\n",
      "|  0.0|[0.76060743809918...|       0.0|[0.82071730762759...|\n",
      "|  0.0|[0.88032369457616...|       0.0|[0.85329072257786...|\n",
      "|  0.0|[0.17641797641473...|       0.0|[0.58730512073999...|\n",
      "|  0.0|[0.32399917012757...|       0.0|[0.65655925156790...|\n",
      "|  0.0|[0.34278688528881...|       0.0|[0.66498156773402...|\n",
      "+-----+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "The GBT  model accuracy is:0.8398643909282207\n",
      "Test Error = 0.160136\n",
      "cacheNodeIds: If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval. (default: False)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "featureSubsetStrategy: The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto' (default: all)\n",
      "featuresCol: features column name. (default: features)\n",
      "labelCol: label column name. (default: label)\n",
      "lossType: Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic (default: logistic)\n",
      "maxBins: Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature. (default: 32)\n",
      "maxDepth: Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. (default: 5)\n",
      "maxIter: max number of iterations (>= 0). (default: 20, current: 10)\n",
      "maxMemoryInMB: Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size. (default: 256)\n",
      "minInfoGain: Minimum information gain for a split to be considered at a tree node. (default: 0.0)\n",
      "minInstancesPerNode: Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1. (default: 1)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "seed: random seed. (default: -7413997043132220981)\n",
      "stepSize: Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator. (default: 0.1)\n",
      "subsamplingRate: Fraction of the training data used for learning each decision tree, in range (0, 1]. (default: 1.0)\n"
     ]
    }
   ],
   "source": [
    "# imprting machine learning modules\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Creating GBT model\n",
    "gbt = GBTClassifier(maxIter=10)\n",
    "gbtModel = gbt.fit(train_data)\n",
    "\n",
    "# TRansforming the data\n",
    "predictions_gbt = gbtModel.transform(test_data)\n",
    "predictions_gbt.select('label', 'rawPrediction', 'prediction', 'probability').show(10)\n",
    "\n",
    "# Evaluating model performance\n",
    "evaluator_gbt =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"label\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Calculating model accuracy\n",
    "accuracy_gbt = evaluator_gbt.evaluate(predictions_gbt)\n",
    "\n",
    "print(\"The GBT  model accuracy is:\"+ str(accuracy_gbt))\n",
    "\n",
    "model_accuracy[\"GBT\"] = accuracy_gbt\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_gbt))\n",
    " \n",
    "# Use explainParams() to output a list of all parameters and their definitions\n",
    "print(gbt.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[31503.  1679.]\n",
      " [ 5170.  4418.]]\n",
      "The precision of False is  0.8590243503394868\n",
      "The precision of True is  0.7246186649171724\n",
      "The recall of True is  0.46078431372549017\n",
      "The recall of False is  0.9494002772587548\n",
      "0.901954047670174\n",
      "The F1-score is  0.901954047670174\n"
     ]
    }
   ],
   "source": [
    "# Creating the prediction and label rdd\n",
    "predictionAndLabel_gbt = predictions_gbt.select(\"prediction\", \"label\").rdd\n",
    "printMetrics(predictionAndLabel_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Cross Validation method to GBT for performance improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GBT  model accuracy is:0.8451718494271686\n"
     ]
    }
   ],
   "source": [
    "# ParamGridBuilder() used in grid search-based models\n",
    "# Parametric to ParamGridBuilder.addGrid() is a pair.\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, [2, 4, 6])\n",
    "             .addGrid(gbt.maxBins, [20, 60])\n",
    "             .addGrid(gbt.maxIter, [10, 20])\n",
    "             .build())\n",
    "\n",
    "# Creating cross validation model\n",
    "cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid,    evaluator=evaluator, numFolds=5)\n",
    " \n",
    "# Run cross validation\n",
    "cvModel = cv.fit(train_data)\n",
    "predictions_cv = cvModel.transform(test_data)\n",
    "\n",
    "# Calculating model accuracy\n",
    "accuracy_gbt_cv = evaluator_gbt.evaluate(predictions_cv)\n",
    "print(\"The GBT  model accuracy is:\"+ str(accuracy_gbt_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we can see that after implementing Cross Validation Method the accuracy improved from 83% to 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[31503.  1679.]\n",
      " [ 5170.  4418.]]\n",
      "The precision of False is  0.8590243503394868\n",
      "The precision of True is  0.7246186649171724\n",
      "The recall of True is  0.46078431372549017\n",
      "The recall of False is  0.9494002772587548\n",
      "0.901954047670174\n",
      "The F1-score is  0.901954047670174\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabel_gbt_new = predictions_cv.select(\"prediction\", \"label\").rdd\n",
    "printMetrics(predictionAndLabel_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': 0.8293196165536592, 'Random Forest': 0.8283610007014263, 'Logistic Regression': 0.8183773673135375, 'GBT': 0.8398643909282207}\n"
     ]
    }
   ],
   "source": [
    "print(model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting model and their accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_model = pd.DataFrame(list(model_accuracy.items()), columns=['Model', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.829320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.828361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.818377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GBT</td>\n",
       "      <td>0.839864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0        Decision Tree  0.829320\n",
       "1        Random Forest  0.828361\n",
       "2  Logistic Regression  0.818377\n",
       "3                  GBT  0.839864"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_model.plot(x='Model',y='Accuracy',kind='bar')\n",
    "plt.ylim(0.8,0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques to make our models perform better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use a method of bagging where we can build multiple models and then averaging the predictions. the concept of bagging was described by Leo Breiman. In this, we generate multiple dataset by taking random sample from the main dataset. Then using each of these dataset, we build logistic regression model. Finally, we take the average the probability of all logistic models to determine final probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To increase the performance of a random forest, we can tune the model parameters. Such as increasing max_features improve the model performance as it provides higher number of options to be considered, by increasinf the values of n_estimators, higher the number of trees means better performance, increasing the min_sample_leaf size as smaller leaf size causes to capture more noise in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can increase the accuracy of a decision tree model by increasing the min sample per leaf node which will stop the tree from classifying the outliers, we can also create a situation all the features are given a chance to become a decision node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.GBT Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we have used cross validation method above to increase the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* https://blog.zopa.com/2017/07/20/tips-honing-logistic-regression-models/\n",
    "* https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "* https://gallery.azure.ai/Experiment/Evaluating-and-Parameter-Tuning-a-Decision-Tree-Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
